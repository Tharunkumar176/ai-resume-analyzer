# AI Resume Analyzer ğŸš€

A comprehensive full-stack application for analyzing resumes using AI and machine learning. The system provides detailed scoring, skill matching, ATS compatibility analysis, and personalized improvement suggestions.

## ğŸ¯ Features

- **User Authentication**: Secure signup/login with JWT
- **Resume Upload**: Support for PDF and DOCX formats
- **AI-Powered Analysis**: 
  - ATS Compatibility Score
  - Keyword Matching
  - Skills Analysis (matched and missing)
  - Experience Evaluation
  - Education Assessment
- **Detailed Feedback**: Personalized suggestions for improvement
- **Analysis History**: Track and compare multiple resume analyses
- **Modern UI**: Responsive design with Tailwind CSS

## ğŸ—ï¸ Architecture

The application consists of three main components:

```
ai-resume-analyzer/
â”œâ”€â”€ ml-api/          # Python FastAPI - ML Analysis Service
â”œâ”€â”€ server/          # Node.js Express - Backend API
â””â”€â”€ client/          # React + Vite - Frontend UI
```

### Technology Stack

**ML API (Python)**
- FastAPI
- scikit-learn
- sentence-transformers
- spaCy
- numpy

**Backend (Node.js)**
- Express.js
- MongoDB with Mongoose
- JWT Authentication
- Multer for file uploads
- pdf-parse & mammoth for file parsing

**Frontend (React)**
- React 18
- React Router
- Vite
- Tailwind CSS
- Axios

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- Node.js 16+
- MongoDB (local or Atlas)

### Installation

#### 1. ML API Setup

```bash
cd ml-api

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On macOS/Linux:
source venv/bin/activate
# On Windows:
# venv\\Scripts\\activate

# Install dependencies
pip install -r requirements.txt

# Start the ML API server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

The ML API will be available at `http://localhost:8000`

#### 2. Backend Server Setup

```bash
cd server

# Install dependencies
npm install

# Create .env file
cp .env.example .env

# Update .env with your MongoDB URI and JWT secret

# Start the server
npm run dev
```

The backend server will be available at `http://localhost:5000`

#### 3. Frontend Client Setup

```bash
cd client

# Install dependencies
npm install

# Create .env file
cp .env.example .env

# Start the development server
npm run dev
```

The frontend will be available at `http://localhost:3000`

## ğŸ“ API Documentation

### ML API Endpoints

- `POST /analyze` - Analyze resume text and return scores
- `GET /health` - Health check
- `GET /` - API information

### Backend API Endpoints

**Authentication**
- `POST /api/auth/signup` - Register new user
- `POST /api/auth/login` - Login user
- `GET /api/auth/profile` - Get user profile (Protected)

**Resume Analysis**
- `POST /api/resume/analyze` - Upload and analyze resume (Protected)
- `GET /api/resume/history` - Get analysis history (Protected)
- `GET /api/resume/analysis/:id` - Get specific analysis (Protected)
- `DELETE /api/resume/analysis/:id` - Delete analysis (Protected)

## ğŸ”‘ Environment Variables

### ML API (.env)
```
PORT=8000
HOST=0.0.0.0
```

### Backend Server (.env)
```
PORT=5000
NODE_ENV=development
MONGODB_URI=mongodb://localhost:27017/resume-analyzer
JWT_SECRET=your_secret_key_here
JWT_EXPIRE=30d
ML_API_URL=http://localhost:8000
```

### Frontend Client (.env)
```
VITE_API_URL=http://localhost:5000/api
```

## ğŸ“Š Project Structure

### ML API
```
ml-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ analyzer.py          # Analysis logic
â”‚   â”œâ”€â”€ models.py            # Pydantic models
â”‚   â””â”€â”€ utils.py             # Utility functions
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### Backend Server
```
server/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ db.js               # MongoDB connection
â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ authController.js   # Authentication logic
â”‚   â””â”€â”€ resumeController.js # Resume handling logic
â”œâ”€â”€ middleware/
â”‚   â”œâ”€â”€ authMiddleware.js   # JWT verification
â”‚   â””â”€â”€ uploadMiddleware.js # File upload handling
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ User.js             # User schema
â”‚   â””â”€â”€ ResumeAnalysis.js   # Analysis schema
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ authRoutes.js       # Auth routes
â”‚   â””â”€â”€ resumeRoutes.js     # Resume routes
â”œâ”€â”€ service/
â”‚   â”œâ”€â”€ pdfParser.js        # PDF text extraction
â”‚   â”œâ”€â”€ docxParser.js       # DOCX text extraction
â”‚   â””â”€â”€ mlService.js        # ML API integration
â”œâ”€â”€ server.js               # Express app
â””â”€â”€ package.json
```

### Frontend Client
```
client/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ FileUpload.jsx
â”‚   â”‚   â”œâ”€â”€ Loader.jsx
â”‚   â”‚   â”œâ”€â”€ Navbar.jsx
â”‚   â”‚   â”œâ”€â”€ ProtectedRoute.jsx
â”‚   â”‚   â””â”€â”€ ScoreCard.jsx
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useAuth.js
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ Dashboard.jsx
â”‚   â”‚   â”œâ”€â”€ Login.jsx
â”‚   â”‚   â”œâ”€â”€ ResultPage.jsx
â”‚   â”‚   â”œâ”€â”€ Signup.jsx
â”‚   â”‚   â””â”€â”€ UploadResume.jsx
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ api.js          # Axios instance
â”‚   â”‚   â”œâ”€â”€ authService.js  # Auth API calls
â”‚   â”‚   â””â”€â”€ resumeService.js # Resume API calls
â”‚   â”œâ”€â”€ App.jsx
â”‚   â”œâ”€â”€ main.jsx
â”‚   â””â”€â”€ index.css
â”œâ”€â”€ index.html
â”œâ”€â”€ package.json
â”œâ”€â”€ tailwind.config.js
â””â”€â”€ vite.config.js
```

## ğŸ”„ Application Flow

1. **User Registration/Login**
   - User signs up or logs in through the React frontend
   - Backend validates credentials and returns JWT token
   - Token is stored in localStorage for subsequent requests

2. **Resume Upload**
   - User uploads PDF/DOCX resume file
   - Optional: Add job description for targeted analysis
   - Frontend sends multipart form data to backend

3. **File Processing**
   - Backend receives file via Multer middleware
   - File type detection (PDF/DOCX)
   - Text extraction using pdf-parse or mammoth
   - Validation of extracted text

4. **ML Analysis**
   - Backend sends extracted text to ML API
   - ML API performs comprehensive analysis:
     - ATS compatibility scoring
     - Keyword extraction and matching
     - Skills detection and matching
     - Experience evaluation
     - Education assessment
     - Suggestion generation
   - Returns structured JSON response

5. **Data Storage**
   - Backend saves analysis results to MongoDB
   - Associates data with user account
   - Returns response to frontend

6. **Results Display**
   - Frontend displays comprehensive analysis:
     - Overall score with color-coded cards
     - Score breakdown (ATS, keywords, skills, experience, education)
     - Matched and missing skills
     - Extracted keywords
     - Improvement suggestions

7. **History Management**
   - Users can view past analyses on Dashboard
   - Filter, sort, and delete old analyses
   - Re-view detailed results anytime

## ğŸ§ª Testing

### Test ML API
```bash
curl -X POST "http://localhost:8000/analyze" \
  -H "Content-Type: application/json" \
  -d '{
    "resume_text": "Experienced Software Engineer with 5 years in Python, JavaScript, React, Node.js...",
    "job_description": "Looking for a Full Stack Developer with React and Node.js experience..."
  }'
```

### Test Backend API
```bash
# Signup
curl -X POST "http://localhost:5000/api/auth/signup" \
  -H "Content-Type: application/json" \
  -d '{"name":"John Doe","email":"john@example.com","password":"password123"}'

# Login
curl -X POST "http://localhost:5000/api/auth/login" \
  -H "Content-Type: application/json" \
  -d '{"email":"john@example.com","password":"password123"}'
```

## ğŸ› ï¸ Development

### Running in Development Mode

Start all three services in separate terminals:

```bash
# Terminal 1 - ML API
cd ml-api
source venv/bin/activate
uvicorn app.main:app --reload

# Terminal 2 - Backend
cd server
npm run dev

# Terminal 3 - Frontend
cd client
npm run dev
```

## ğŸ“¦ Production Deployment

### Build Frontend
```bash
cd client
npm run build
```

### Deploy ML API
- Use services like AWS EC2, Google Cloud Run, or Heroku
- Ensure Python 3.8+ is installed
- Set up environment variables
- Use gunicorn or uvicorn for production

### Deploy Backend
- Deploy to AWS, Heroku, or DigitalOcean
- Use MongoDB Atlas for cloud database
- Set NODE_ENV=production
- Configure CORS for production domains

### Deploy Frontend
- Use Vercel, Netlify, or AWS S3 + CloudFront
- Update VITE_API_URL to production backend URL

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¥ Support

For issues and questions, please open an issue in the repository.

---

Built with â¤ï¸ using React, Node.js, FastAPI, and MongoDB
# ai-resume-analyzer
